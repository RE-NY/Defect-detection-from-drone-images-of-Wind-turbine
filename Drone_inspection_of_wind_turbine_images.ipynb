{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YE8zbgBnr5-FFsQyiJTK8ZPLvnoKHRDo",
      "authorship_tag": "ABX9TyMbFjpj1n28Rh15lEuIYgHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RE-NY/Defect-detection-from-drone-images-of-Wind-turbine/blob/main/Drone_inspection_of_wind_turbine_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as _Imgdis\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "0j1Rh80h8StZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def give_dataset(folder):\n",
        "  onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
        "\n",
        "  print(\"Working with {0} images\".format(len(onlyfiles)))\n",
        "  #print(\"Image examples: \")\n",
        "\n",
        "  #for i in range(2):\n",
        "  #   print(onlyfiles[i])\n",
        "    #  display(_Imgdis(filename=folder + \"/\" + onlyfiles[i], width=240, height=320))\n",
        "  onlyfiles[1]\n",
        "  type(onlyfiles[1])\n",
        "\n",
        "  from scipy import ndimage\n",
        "  from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "  train_files = []\n",
        "  i=0\n",
        "  for _file in onlyfiles:\n",
        "      train_files.append(_file)\n",
        "      label_in_file = _file.find(\"_\")\n",
        "  print(\"Files in train_files: %d\" % len(train_files))\n",
        "\n",
        "  # Original Dimensions      #2970 #5280 #3\n",
        "  image_width = 5280\n",
        "  image_height = 2970\n",
        "  ratio = 4\n",
        "\n",
        "  image_width = int(image_width / ratio) - 1\n",
        "  image_height = int(image_height / ratio)\n",
        "\n",
        "  channels = 3\n",
        "  nb_classes = 1\n",
        "\n",
        "  dataset = np.ndarray(shape=(len(train_files), image_width , image_height , channels),\n",
        "                      dtype=np.float32)\n",
        "\n",
        "  i = 0\n",
        "  for _file in train_files:\n",
        "      img = load_img(folder + \"/\" + _file)  # this is a PIL image\n",
        "      img.thumbnail((image_width, image_height))\n",
        "      # Convert to Numpy Array\n",
        "      x = img_to_array(img)\n",
        "      x = x.reshape((1319 , 742 , 3))\n",
        "      # Normalize\n",
        "      x = (x - 128.0) / 128.0\n",
        "      dataset[i] = x\n",
        "      i += 1\n",
        "      if i % 250 == 0:\n",
        "          print(\"%d images to array\" % i)\n",
        "  #print(\"All images to array!\")\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "0_8sLw6YH2_L"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = give_dataset(\"/content/drive/MyDrive/Image folder\")\n",
        "#print((dataset))"
      ],
      "metadata": {
        "id": "dzWwogbeIPat"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making X_train.......\n",
        "'''\n",
        "X_train_correct = dataset_correct\n",
        "X_train_defected = dataset_defected\n",
        "X_train = sum of those...\n",
        "\n",
        "y_train_correct = np.full((1,#total examples) , 1 , dtype = int)\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Z805SAxJzta5",
        "outputId": "b643b1dc-00fb-4545-db9c-97dec486592e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX_train_correct = dataset_correct\\nX_train_defected = dataset_defected\\nX_train = sum of those...\\n\\ny_train_correct = np.full((1,#total examples) , 1 , dtype = int)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_correct = give_dataset(\"/content/drive/MyDrive/Correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBrOq_iq9fhs",
        "outputId": "7c983e61-18e7-4655-b0cf-0811b2d449fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with 40 images\n",
            "Files in train_files: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_defected = give_dataset(\"/content/drive/MyDrive/Defected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku4Hz-FI9jZ0",
        "outputId": "15b164d3-1dcb-42eb-a092-fbf026c016ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with 40 images\n",
            "Files in train_files: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_correct = np.full((1 , len(X_train_correct)) , 1)\n",
        "y_train_defected = np.full((1 , len(X_train_correct)) , 0)\n"
      ],
      "metadata": {
        "id": "qshPbPfC9jjo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenation....\n",
        "X_train = np.concatenate((X_train_correct , X_train_defected) , axis = 0)\n",
        "\n"
      ],
      "metadata": {
        "id": "oKfhtPAL_Jbz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.concatenate((y_train_correct , y_train_defected) , axis = 1)"
      ],
      "metadata": {
        "id": "4oPZ9rUn_JmN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape((80,1))\n",
        "#y_train"
      ],
      "metadata": {
        "id": "w-g_0G5XUfcj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the split to make final data.....\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=33)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=33)\n",
        "print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Tse8LQ_JxF",
        "outputId": "8532428a-ec23-4b56-aa90-9e1cd81a5565"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 64, Val set size: 8, Test set size: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GaYq4BzL_J6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fvzgEFOt_KFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#self made model....not used instead the model below vgg19 is used......\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras import backend as k\n",
        "\n",
        "#inpx = Input(shape=(1319 , 742 , 3))\n",
        "#layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)\n",
        "#layer2 = Conv2D(32, (3, 3), activation='relu')(layer1)\n",
        "#layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
        "#layer4 = Dropout(0.5)(layer3)\n",
        "#layer5 = Flatten()(layer4)\n",
        "# #layer6 = Dense(512, activation='relu')(layer5)\n",
        "#layer6 = Dense(1 , activation='sigmoid')(layer5)\n",
        "\n",
        "#model = Model([inpx], layer6)\n",
        "#model.compile(optimizer=keras.optimizers.Adadelta(),\n",
        "#              loss=keras.losses.categorical_crossentropy,\n",
        "#              metrics=['accuracy'])\n",
        "#model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ5nRvMFztwv",
        "outputId": "0c1cd4a9-ef00-4b55-e4a9-01a09de783e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1319, 742, 3)]    0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 1317, 740, 32)     896       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1315, 738, 32)     9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 438, 246, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 438, 246, 32)      0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3447936)           0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3447937   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3458081 (13.19 MB)\n",
            "Trainable params: 3458081 (13.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will use this model...VGG19\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "vgg = tf.keras.applications.vgg19.VGG19(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(1319 , 742 , 3),\n",
        "    pooling=max,\n",
        ")\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = Flatten()(vgg.output)\n",
        "prediction = Dense(1 , activation = \"sigmoid\")(x)\n",
        "\n",
        "model = Model(inputs = vgg.input , outputs = prediction)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYxtG_LcDmx8",
        "outputId": "6995acb5-7b12-4727-fe8b-bc7bea41806a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <keras.src.engine.functional.Functional object at 0x7e905c599e70>>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKNF1ouNWB7F",
        "outputId": "1d13e0fc-8883-4384-a0e0-93929352b82c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 1319, 742, 3)\n",
            "(64, 1)\n",
            "(8, 1319, 742, 3)\n",
            "(8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Pussnh2WCJC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50 ,batch_size = 16, validation_data = (X_val , y_val))"
      ],
      "metadata": {
        "id": "ZBBAA60RBsb0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test , y_test , batch_size = 4)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7OhJkoiBsm5",
        "outputId": "8a6ee716-58c8-461e-d0a8-0a9c253ae829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 46ms/step - loss: 0.0000e+00 - accuracy: 0.3750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.375]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For Data augmentation..............\n",
        "# Importing necessary functions\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "#from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
        "\n",
        "# Initialising the ImageDataGenerator class.\n",
        "# We will pass in the augmentation parameters in the constructor.\n",
        "#datagen = ImageDataGenerator(\n",
        "#    horizontal_flip = True,\n",
        "#\t\trotation_range = 40,\n",
        "#\t\tshear_range = 0.2,\n",
        "#\t\tzoom_range = 0.2,\n",
        "#\t\tbrightness_range = (0.5, 1.5))\n",
        "\n",
        "# Loading a sample image\n",
        "#img = load_img('/content/drive/MyDrive/Correct/DJI_0590.JPG')\n",
        "# Converting the input sample image to an array\n",
        "#x = img_to_array(img)\n",
        "# Reshaping the input image\n",
        "#x = x.reshape((1, ) + x.shape)\n",
        "\n",
        "# Generating and saving 5 augmented samples\n",
        "# using the above defined parameters.\n",
        "#i = 0\n",
        "#for batch in datagen.flow(x, batch_size = 1,\n",
        "#\t\t\t\t\t\tsave_to_dir ='/content/drive/MyDrive/Colab Notebooks',\n",
        "#\t\t\t\t\t\tsave_prefix ='image', save_format ='JPG'):\n",
        "#\ti += 1\n",
        "#\tif i > 2: # gives three including itself.....\n",
        "#\t\tbreak"
      ],
      "metadata": {
        "id": "Dp99upoNKD3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HLh_Vo6KECF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5eOOpM4CKEMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rttZWrxPKFOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6uzsmCiKFZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyaIVlRTKFj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gOvUaTctKFuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AV_tOwbPKF4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q1fCvLcoKGB0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}