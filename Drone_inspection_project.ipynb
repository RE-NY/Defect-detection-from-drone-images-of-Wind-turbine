{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YE8zbgBnr5-FFsQyiJTK8ZPLvnoKHRDo",
      "authorship_tag": "ABX9TyPuH8gLvRTBcn4E/T2pB0uL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RE-NY/Defect-detection-from-drone-images-of-Wind-turbine/blob/main/Drone_inspection_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as _Imgdis\n",
        "from PIL import Image\n",
        "from time import time\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "0j1Rh80h8StZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def give_dataset(folder):\n",
        "  onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
        "\n",
        "  print(\"Working with {0} images\".format(len(onlyfiles)))\n",
        "  #print(\"Image examples: \")\n",
        "\n",
        "  #for i in range(2):\n",
        "  #   print(onlyfiles[i])\n",
        "    #  display(_Imgdis(filename=folder + \"/\" + onlyfiles[i], width=240, height=320))\n",
        "  onlyfiles[1]\n",
        "  type(onlyfiles[1])\n",
        "\n",
        "  from scipy import ndimage\n",
        "  from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "  train_files = []\n",
        "  i=0\n",
        "  for _file in onlyfiles:\n",
        "      train_files.append(_file)\n",
        "      label_in_file = _file.find(\"_\")\n",
        "  print(\"Files in train_files: %d\" % len(train_files))\n",
        "\n",
        "  # Original Dimensions      #2970 #5280 #3\n",
        "  image_width = 5280\n",
        "  image_height = 2970\n",
        "  ratio = 4\n",
        "\n",
        "  image_width = int(image_width / ratio) - 1\n",
        "  image_height = int(image_height / ratio)\n",
        "\n",
        "  channels = 3\n",
        "  nb_classes = 1\n",
        "\n",
        "  dataset = np.ndarray(shape=(len(train_files), image_width , image_height , channels),\n",
        "                      dtype=np.float32)\n",
        "\n",
        "  i = 0\n",
        "  for _file in train_files:\n",
        "      img = load_img(folder + \"/\" + _file)  # this is a PIL image\n",
        "      img.thumbnail((image_width, image_height))\n",
        "      # Convert to Numpy Array\n",
        "      x = img_to_array(img)\n",
        "      x = x.reshape((1319 , 742 , 3))\n",
        "      # Normalize\n",
        "      x = (x - 128.0) / 128.0\n",
        "      dataset[i] = x\n",
        "      i += 1\n",
        "      if i % 250 == 0:\n",
        "          print(\"%d images to array\" % i)\n",
        "  #print(\"All images to array!\")\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "0_8sLw6YH2_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = give_dataset(\"/content/drive/MyDrive/Image folder\")\n",
        "#print((dataset))"
      ],
      "metadata": {
        "id": "dzWwogbeIPat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making X_train.......\n",
        "'''\n",
        "X_train_correct = dataset_correct\n",
        "X_train_defected = dataset_defected\n",
        "X_train = sum of those...\n",
        "\n",
        "y_train_correct = np.full((1,#total examples) , 1 , dtype = int)\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Z805SAxJzta5",
        "outputId": "02fa09ba-a7c7-4b35-faf9-0d822910146f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX_train_correct = dataset_correct\\nX_train_defected = dataset_defected\\nX_train = sum of those...\\n\\ny_train_correct = np.full((1,#total examples) , 1 , dtype = int)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_correct = give_dataset(\"/content/drive/MyDrive/Correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBrOq_iq9fhs",
        "outputId": "a6528c9c-d238-40f4-d242-79469efa7fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with 40 images\n",
            "Files in train_files: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_defected = give_dataset(\"/content/drive/MyDrive/Defected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku4Hz-FI9jZ0",
        "outputId": "65e5c16d-076f-4e00-dc21-b827ea5d6290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with 40 images\n",
            "Files in train_files: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_correct = np.full((1 , len(X_train_correct)) , 1)\n",
        "y_train_defected = np.full((1 , len(X_train_correct)) , 0)\n"
      ],
      "metadata": {
        "id": "qshPbPfC9jjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenation....\n",
        "X_train = np.concatenate((X_train_correct , X_train_defected) , axis = 0)\n",
        "\n"
      ],
      "metadata": {
        "id": "oKfhtPAL_Jbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.concatenate((y_train_correct , y_train_defected) , axis = 1)"
      ],
      "metadata": {
        "id": "4oPZ9rUn_JmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape((80,1))\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "w-g_0G5XUfcj",
        "outputId": "baa4f1b1-d8f4-498a-ac1a-a89e03a81717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9d31a312c6fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 64 into shape (80,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the split to make final data.....\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=33)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=33)\n",
        "print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Tse8LQ_JxF",
        "outputId": "40a3f80e-0cd2-4a80-e9da-3bea73529286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 64, Val set size: 8, Test set size: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GaYq4BzL_J6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fvzgEFOt_KFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras import backend as k\n",
        "\n",
        "inpx = Input(shape=(1319 , 742 , 3))\n",
        "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)\n",
        "layer2 = Conv2D(32, (3, 3), activation='relu')(layer1)\n",
        "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
        "layer4 = Dropout(0.5)(layer3)\n",
        "layer5 = Flatten()(layer4)\n",
        "#layer6 = Dense(512, activation='relu')(layer5)\n",
        "layer6 = Dense(1 , activation='sigmoid')(layer5)\n",
        "\n",
        "model = Model([inpx], layer6)\n",
        "model.compile(optimizer=keras.optimizers.Adadelta(),\n",
        "              loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ5nRvMFztwv",
        "outputId": "0c1cd4a9-ef00-4b55-e4a9-01a09de783e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1319, 742, 3)]    0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 1317, 740, 32)     896       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1315, 738, 32)     9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 438, 246, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 438, 246, 32)      0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3447936)           0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3447937   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3458081 (13.19 MB)\n",
            "Trainable params: 3458081 (13.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKNF1ouNWB7F",
        "outputId": "60c0a246-be4a-4331-afa9-58c93fa1ce1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 1319, 742, 3)\n",
            "(64, 1)\n",
            "(8, 1319, 742, 3)\n",
            "(8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Pussnh2WCJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50 ,batch_size = 16, validation_data = (X_val , y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBBAA60RBsb0",
        "outputId": "966c2fdb-cb3c-4bff-b6ba-f43eaadeb125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.5469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 20s 2s/step - loss: 0.0000e+00 - accuracy: 0.5469 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 4s 926ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 4s 919ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 4s 964ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 4s 927ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 4s 936ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 4s 931ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 4s 951ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 4s 980ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 4s 947ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 4s 943ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 4s 971ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 4s 946ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 4s 941ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 4s 983ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 4s 954ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 4s 944ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 4s 937ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 4s 966ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 4s 968ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 4s 944ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 4s 942ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 4s 950ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 4s 945ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 4s 948ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 4s 957ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 4s 966ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 4s 980ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 4s 951ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 4s 960ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 4s 969ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 4s 965ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 4s 960ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 4s 986ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 4s 979ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 4s 957ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 4s 957ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 4s 967ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 4s 994ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 4s 971ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 4s 964ms/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0000e+00 - accuracy: 0.5156 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a413c599bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test , y_test , batch_size = 4)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7OhJkoiBsm5",
        "outputId": "8a6ee716-58c8-461e-d0a8-0a9c253ae829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 46ms/step - loss: 0.0000e+00 - accuracy: 0.3750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.375]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dp99upoNKD3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HLh_Vo6KECF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5eOOpM4CKEMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Data augmentation..............\n",
        "# Importing necessary functions\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
        "\n",
        "# Initialising the ImageDataGenerator class.\n",
        "# We will pass in the augmentation parameters in the constructor.\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "\t\trotation_range = 40,\n",
        "\t\tshear_range = 0.2,\n",
        "\t\tzoom_range = 0.2,\n",
        "\t\tbrightness_range = (0.5, 1.5))\n",
        "\n",
        "# Loading a sample image\n",
        "img = load_img('/content/drive/MyDrive/Correct/DJI_0590.JPG')\n",
        "# Converting the input sample image to an array\n",
        "x = img_to_array(img)\n",
        "# Reshaping the input image\n",
        "x = x.reshape((1, ) + x.shape)\n",
        "\n",
        "# Generating and saving 5 augmented samples\n",
        "# using the above defined parameters.\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size = 1,\n",
        "\t\t\t\t\t\tsave_to_dir ='/content/drive/MyDrive/Colab Notebooks',\n",
        "\t\t\t\t\t\tsave_prefix ='image', save_format ='JPG'):\n",
        "\ti += 1\n",
        "\tif i > 2: # gives three including itself.....\n",
        "\t\tbreak\n"
      ],
      "metadata": {
        "id": "HeKFD9pqBsxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rttZWrxPKFOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6uzsmCiKFZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyaIVlRTKFj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gOvUaTctKFuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AV_tOwbPKF4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q1fCvLcoKGB0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}